Reading date: 20241001

Paper Title: DIFFUCOMET: Contextual Commonsense Knowledge Diffusion

Label: cs.CL

Challenge: Inferring contextually-relevant and diverse commonsense to understand narratives remains challenging for knowledge models.

Storyline: 

1. Identifying the commonsense inferences that underlie narratives, (such as stories or dialogues) is crucial to understanding those same narratives.

   e.g. to understand why "Hank ... got the shopping bags", need to infer that (1) Hank was not finished wrapping wrapping paper, and (2) so would need to buy more wrapping paper.

   However, comprehensively inferring these diverse,  yet implicit, commonsense inferences that are relevant to a context remains a challenging task.

2. Recent methods for identifying contextually relevant commonsense inferences use knowledge models to generate commonsense facts.

3. While knowledge models have been less brittle than previous retrieval-based methods, they have two major shortcomings.

   1. Contextually-irrelevant.
   2. Using autoregressive training objectives. Only identify limited collections of commonsense inferences relevant to  an input context.

4. Proposing DIFFUCOMET. 

   1. Using diffusion-based decoding to generate relevant knowledge embeddings that are constrained to the narrative context.

5. Using traditional NLG metrics to evaluate DIFFUCOMET. However, these metrics focus on surface form matching to gold references, and fall short of me

6. A novel set of metrics that access diversity and contextual relevance of knowledge generated by knowledge models.

Task: According to a narrative sample S as text to generate commonsense inferences as a set facts K.

Input: S (narrative sample)

Output: facts K = {k_1, k_2, ...},k_n = (h_n, r_n, a_n)

